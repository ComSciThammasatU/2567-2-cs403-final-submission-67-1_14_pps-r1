# -*- coding: utf-8 -*-
"""apppp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JmjEatBiyaORRZT7iWwXfPZgUA9bBVKs
"""

import pandas as pd
import os
from transformers import BertTokenizer, BertForTokenClassification, AutoTokenizer
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from seqeval.metrics import classification_report # For sequence tagging evaluation
import numpy as np
import torch.nn as nn
from collections import defaultdict
import shutil
import sys
import tqdm.notebook as tq

import torch
import torch.nn as nn
from torch.optim import AdamW

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

from flask import Flask, request, render_template
from transformers import pipeline, BertTokenizer, BertModel
import torch
import torch.nn as nn
import re
from markupsafe import Markup

# ==== Flask Setup ====
app = Flask(__name__)

# ==== Load your BERT models here ====
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class BERTClass(nn.Module):
    def __init__(self, num_labels):
        super(BERTClass, self).__init__()
        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)
        self.dropout = nn.Dropout(0.4)
        self.linear = nn.Linear(768, num_labels)

    def forward(self, input_ids, attention_mask, token_type_ids):
        output = self.bert_model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )
        pooled_output = self.dropout(output.pooler_output)
        return self.linear(pooled_output)

# Load tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Load aspect classification model
aspect_model = BERTClass(num_labels=5)
aspect_model.load_state_dict(torch.load('MLTC_model_state.bin', map_location=device))
aspect_model.to(device)
aspect_model.eval()

# Load sentiment classification model
sentiment_model = BERTClass(num_labels=3)
sentiment_model.load_state_dict(torch.load('Sentiment_model_state.bin', map_location=device))
sentiment_model.to(device)
sentiment_model.eval()

aspect_classes = ['ambience', 'anecdotes/miscellaneous', 'food', 'price', 'service']
sentiment_classes = ['negative', 'neutral', 'positive']

ate_pipeline = pipeline("token-classification", model="gauneg/roberta-base-absa-ate-sentiment", aggregation_strategy="none")

def get_color(sentiment_index):
    return {0: 'red', 1: 'orange', 2: 'green'}.get(sentiment_index, 'black')

def extract_aspect_terms(text):
    ner_result = ate_pipeline(text)
    aspect_terms = []
    current_term = []
    for r in ner_result:
        label, word = r['entity'], r['word']
        if label.startswith("B"):
            if current_term: aspect_terms.append(" ".join(current_term)); current_term = []
            current_term.append(word)
        elif label.startswith("I"):
            current_term.append(word)
        else:
            if current_term: aspect_terms.append(" ".join(current_term)); current_term = []
    if current_term: aspect_terms.append(" ".join(current_term))
    return list(set([term.replace("Ä ", "").strip() for term in aspect_terms]))

def extract_context(text, term, window_size=6):
    tokens = text.split()
    for i, token in enumerate(tokens):
        if term.lower() in token.lower():
            start = max(i - window_size // 2, 0)
            end = min(i + window_size // 2 + 1, len(tokens))
            return ' '.join(tokens[start:end])
    return text

def analyze_text(text):
    html_text = text
    results = []
    aspect_terms = extract_aspect_terms(text)

    for term in aspect_terms:
        if re.search(re.escape(term), text, re.IGNORECASE):
            context = extract_context(text, term)

            inputs = tokenizer.encode_plus(
                text=context,
                text_pair=term,
                max_length=96,
                padding='max_length',
                truncation=True,
                return_tensors='pt'
            )
            input_ids = inputs['input_ids'].to(device)
            attention_mask = inputs['attention_mask'].to(device)
            token_type_ids = inputs['token_type_ids'].to(device)

            with torch.no_grad():
                aspect_output = aspect_model(input_ids, attention_mask, token_type_ids)
                aspect_probs = torch.sigmoid(aspect_output)
                aspect_indices = (aspect_probs > 0.5).nonzero(as_tuple=True)[1].tolist()
                aspect_labels = [aspect_classes[i] for i in aspect_indices] if aspect_indices else ['(none)']

                sentiment_output = sentiment_model(input_ids, attention_mask, token_type_ids)
                _, sentiment_pred = torch.max(sentiment_output, dim=1)
                sentiment_label = sentiment_classes[sentiment_pred.item()]
                sentiment_color = get_color(sentiment_pred.item())

            colored_term = f"<span style='color:{sentiment_color}; font-weight:bold'>{term}</span>"
            html_text = re.sub(f"(?i){re.escape(term)}", colored_term, html_text)

            results.append({
                'term': term,
                'aspect': aspect_labels,
                'sentiment': sentiment_label
            })

    return Markup(f"<p style='font-size:18px'>{html_text}</p>"), results

@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        text = request.form['text']
        html_result, terms = analyze_text(text)
        return render_template('index.html', input_text=text, html_result=html_result, terms=terms)
    return render_template('index.html')

if __name__ == '__main__':
    app.run(debug=True)
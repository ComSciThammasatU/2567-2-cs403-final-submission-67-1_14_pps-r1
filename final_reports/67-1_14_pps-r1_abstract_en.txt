This research focuses on the development and comparison of Aspect-Based Sentiment Analysis (ABSA) models for English text reviews. It presents an analysis and application of models from three different generations: TF-IDF combined with Support Vector Machine (SVM), Word2vec combined with Long Short-Term Memory (LSTM), and Fine-tuned BERT. These models are employed for both Aspect Classification, which is a multi-label task, and Sentiment Classification, which is a multi-class task, to achieve more granular analytical results.
The study covers the theoretical concepts underpinning each model, including specific details on training earlier generation models. For instance, it details the application of MultiLabelBinarizer() with OneVsRestClassifier() for TF-IDF + SVM. For the Word2vec + LSTM model, pre-trained Word Embeddings from GoogleNews-vectors-negative300.bin were utilized, with the Embedding Layer being frozen to leverage the pre-learned knowledge. For the Fine-tuned BERT model, the report explains the BERT-specific Tokenization process and the fine-tuning of the pre-trained bert-base-uncased model.
Experimental results demonstrate that the Fine-tuned BERT model exhibits superior performance compared to the other models across almost all aspects and sentiment categories, in terms of both Accuracy and F1-score. This superiority reflects the model's deep contextual understanding capabilities. Furthermore, the report describes a method for color-coded visualization of ABSA results, which enables users to clearly understand and interpret the analysis.
Keywords: Aspect-Based Sentiment Analysis, TF-IDF, SVM, Word2vec, LSTM, BERT, Color-coded Visualization
